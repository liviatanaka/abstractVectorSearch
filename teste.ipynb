{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook destinado para a realização de testes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\livia\\OneDrive\\Área de Trabalho\\inspe\\6_semestre\\env\\lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\livia\\OneDrive\\Área de Trabalho\\inspe\\6_semestre\\env\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ======= Importando bibliotecas ======= #\n",
    "# gerais\n",
    "import pandas as pd\n",
    "\n",
    "# NLP, deep learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import normalize\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from classes.Transformador import Transformador\n",
    "\n",
    "# visualização\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm # This will make a progress bar for us\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>abstract</th>\n",
       "      <th>categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bosonic characters of atomic Cooper pairs acro...</td>\n",
       "      <td>Y. H. Pong and C. K. Law</td>\n",
       "      <td>We study the two-particle wave function of p...</td>\n",
       "      <td>cond-mat.mes-hall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Measurement of the Hadronic Form Factor in D0 ...</td>\n",
       "      <td>The BABAR Collaboration, B. Aubert, et al</td>\n",
       "      <td>The shape of the hadronic form factor f+(q2)...</td>\n",
       "      <td>hep-ex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spectroscopic Properties of Polarons in Strong...</td>\n",
       "      <td>A. S. Mishchenko (1 and 2) and N. Nagaosa (1 a...</td>\n",
       "      <td>We present recent advances in understanding ...</td>\n",
       "      <td>cond-mat.str-el cond-mat.stat-mech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tuning correlation effects with electron-phono...</td>\n",
       "      <td>J.P.Hague and N.d'Ambrumenil</td>\n",
       "      <td>We investigate the effect of tuning the phon...</td>\n",
       "      <td>cond-mat.str-el</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Convergence of the discrete dipole approximati...</td>\n",
       "      <td>Maxim A. Yurkin, Valeri P. Maltsev, Alfons G. ...</td>\n",
       "      <td>We performed a rigorous theoretical converge...</td>\n",
       "      <td>physics.optics physics.comp-ph</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Bosonic characters of atomic Cooper pairs acro...   \n",
       "1  Measurement of the Hadronic Form Factor in D0 ...   \n",
       "2  Spectroscopic Properties of Polarons in Strong...   \n",
       "3  Tuning correlation effects with electron-phono...   \n",
       "4  Convergence of the discrete dipole approximati...   \n",
       "\n",
       "                                             authors  \\\n",
       "0                           Y. H. Pong and C. K. Law   \n",
       "1          The BABAR Collaboration, B. Aubert, et al   \n",
       "2  A. S. Mishchenko (1 and 2) and N. Nagaosa (1 a...   \n",
       "3                       J.P.Hague and N.d'Ambrumenil   \n",
       "4  Maxim A. Yurkin, Valeri P. Maltsev, Alfons G. ...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0    We study the two-particle wave function of p...   \n",
       "1    The shape of the hadronic form factor f+(q2)...   \n",
       "2    We present recent advances in understanding ...   \n",
       "3    We investigate the effect of tuning the phon...   \n",
       "4    We performed a rigorous theoretical converge...   \n",
       "\n",
       "                           categories  \n",
       "0                   cond-mat.mes-hall  \n",
       "1                              hep-ex  \n",
       "2  cond-mat.str-el cond-mat.stat-mech  \n",
       "3                     cond-mat.str-el  \n",
       "4      physics.optics physics.comp-ph  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carregar o dataset e modelo\n",
    "df = pd.read_csv('data/arxiv3.csv')\n",
    "\n",
    "df = df.drop(columns=['Unnamed: 0', 'update_date'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Finder():\n",
    "    def __init__(self, df, embeddings_matrix, model, transformador, tuned_matrix):\n",
    "        self.df = df\n",
    "        self.embeddings_matrix = embeddings_matrix\n",
    "        self.tuned_matrix = tuned_matrix\n",
    "        self.model = model\n",
    "        self.transformador = transformador\n",
    "\n",
    "    def predict_query(self, query, tuned=False, limit=0.5):\n",
    "        query_processed = self.model.encode([query])\n",
    "\n",
    "        if tuned:\n",
    "            query_processed = self.transformador(torch.tensor(query_processed))[1].detach().numpy()\n",
    "            embeddings_matrix_ = normalize(self.tuned_matrix)\n",
    "        else:\n",
    "            embeddings_matrix_ = normalize(self.embeddings_matrix)\n",
    "\n",
    "        query_processed_ = normalize(query_processed.reshape(1, -1))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        R = embeddings_matrix_ @ query_processed_.T\n",
    "\n",
    "        df_ = self.df.copy()\n",
    "        relevance = R.flatten()\n",
    "        df_[\"relevance\"] = relevance\n",
    "\n",
    "        df_filtered = df_[relevance > limit]\n",
    "        df_final = df_filtered.sort_values(\"relevance\", ascending=False)\n",
    "\n",
    "        # Selecionar colunas de interesse\n",
    "        df_final = df_final[['title', 'abstract', 'relevance']]\n",
    "\n",
    "        # print the top 10 abstracts\n",
    "        tam = min(10, len(df_final))\n",
    "        for i in range(tam):\n",
    "            print(df_final['abstract'].iloc[i])\n",
    "            print('-----------------------------------')\n",
    "            \n",
    "        return df_final.head(10)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\livia\\AppData\\Local\\Temp\\ipykernel_14444\\283277286.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  embeddings = torch.load('model_embedding/embeddings_bert.pt')\n",
      "C:\\Users\\livia\\AppData\\Local\\Temp\\ipykernel_14444\\283277286.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  X_tuned = torch.load('model_embedding/embeddings_transformados.pt')\n",
      "C:\\Users\\livia\\AppData\\Local\\Temp\\ipykernel_14444\\283277286.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('model_embedding/modelo.pth'))\n",
      "C:\\Users\\livia\\AppData\\Local\\Temp\\ipykernel_14444\\283277286.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  transformador.load_state_dict(torch.load('model_embedding/transformador.pth'))\n"
     ]
    }
   ],
   "source": [
    "embeddings = torch.load('model_embedding/embeddings_bert.pt')\n",
    "X_tuned = torch.load('model_embedding/embeddings_transformados.pt')\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "model.load_state_dict(torch.load('model_embedding/modelo.pth'))\n",
    "transformador = Transformador(\n",
    "    n_inputs=384,\n",
    "    n_hidden=200\n",
    ")\n",
    "transformador.load_state_dict(torch.load('model_embedding/transformador.pth'))\n",
    "\n",
    "finder = Finder(df, embeddings, model, transformador, X_tuned )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  An associative memory model and a neural network model with a Mexican-hat\n",
      "type interaction are the two most typical attractor networks used in the\n",
      "artificial neural network models. The associative memory model has discretely\n",
      "distributed fixed-point attractors, and achieves a discrete information\n",
      "representation. On the other hand, a neural network model with a Mexican-hat\n",
      "type interaction uses a line attractor to achieves a continuous information\n",
      "representation, which can be seen in the working memory in the prefrontal\n",
      "cortex and columnar activity in the visual cortex. In the present study, we\n",
      "propose a neural network model that achieves discrete and continuous\n",
      "information representation. We use a statistical-mechanical analysis to find\n",
      "that a localized retrieval phase exists in the proposed model, where the memory\n",
      "pattern is retrieved in the localized subpopulation of the network. In the\n",
      "localized retrieval phase, the discrete and continuous information\n",
      "representation is achieved by using the orthogonality of the memory patterns\n",
      "and the neutral stability of fixed points along the positions of the localized\n",
      "retrieval. The obtained phase diagram suggests that the antiferromagnetic\n",
      "interaction and the external field are important for generating the localized\n",
      "retrieval phase.\n",
      "\n",
      "-----------------------------------\n",
      "  Learning behavior of simple perceptrons is analyzed for a teacher-student\n",
      "scenario in which output labels are provided by a teacher network for a set of\n",
      "possibly correlated input patterns, and such that teacher and student networks\n",
      "are of the same type. Our main concern is the effect of statistical\n",
      "correlations among the input patterns on learning performance. For this\n",
      "purpose, we extend to the teacher-student scenario a methodology for analyzing\n",
      "randomly labeled patterns recently developed in {\\em J. Phys. A: Math. Theor.}\n",
      "{\\bf 41}, 324013 (2008). This methodology is used for analyzing situations in\n",
      "which orthogonality of the input patterns is enhanced in order to optimize the\n",
      "learning performance.\n",
      "\n",
      "-----------------------------------\n",
      "  The magnetic diagnostics subsystem of the LISA Technology Package (LTP) on\n",
      "board the LISA PathFinder (LPF) spacecraft includes a set of four tri-axial\n",
      "fluxgate magnetometers, intended to measure with high precision the magnetic\n",
      "field at their respective positions. However, their readouts do not provide a\n",
      "direct measurement of the magnetic field at the positions of the test masses,\n",
      "and hence an interpolation method must be designed and implemented to obtain\n",
      "the values of the magnetic field at these positions. However, such\n",
      "interpolation process faces serious difficulties. Indeed, the size of the\n",
      "interpolation region is excessive for a linear interpolation to be reliable\n",
      "while, on the other hand, the number of magnetometer channels does not provide\n",
      "sufficient data to go beyond the linear approximation. We describe an\n",
      "alternative method to address this issue, by means of neural network\n",
      "algorithms. The key point in this approach is the ability of neural networks to\n",
      "learn from suitable training data representing the behavior of the magnetic\n",
      "field. Despite the relatively large distance between the test masses and the\n",
      "magnetometers, and the insufficient number of data channels, we find that our\n",
      "artificial neural network algorithm is able to reduce the estimation errors of\n",
      "the field and gradient down to levels below 10%, a quite satisfactory result.\n",
      "Learning efficiency can be best improved by making use of data obtained in\n",
      "on-ground measurements prior to mission launch in all relevant satellite\n",
      "locations and in real operation conditions. Reliable information on that\n",
      "appears to be essential for a meaningful assessment of magnetic noise in the\n",
      "LTP.\n",
      "\n",
      "-----------------------------------\n",
      "  Self-organizing networks such as Neural Gas, Growing Neural Gas and many\n",
      "others have been adopted in actual applications for both dimensionality\n",
      "reduction and manifold learning. Typically, in these applications, the\n",
      "structure of the adapted network yields a good estimate of the topology of the\n",
      "unknown subspace from where the input data points are sampled. The approach\n",
      "presented here takes a different perspective, namely by assuming that the input\n",
      "space is a manifold of known dimension. In return, the new type of growing\n",
      "self-organizing network presented gains the ability to adapt itself in way that\n",
      "may guarantee the effective and stable recovery of the exact topological\n",
      "structure of the input manifold.\n",
      "\n",
      "-----------------------------------\n",
      "  A fundamental problem in neuroscience is understanding how working memory --\n",
      "the ability to store information at intermediate timescales, like 10s of\n",
      "seconds -- is implemented in realistic neuronal networks. The most likely\n",
      "candidate mechanism is the attractor network, and a great deal of effort has\n",
      "gone toward investigating it theoretically. Yet, despite almost a quarter\n",
      "century of intense work, attractor networks are not fully understood. In\n",
      "particular, there are still two unanswered questions. First, how is it that\n",
      "attractor networks exhibit irregular firing, as is observed experimentally\n",
      "during working memory tasks? And second, how many memories can be stored under\n",
      "biologically realistic conditions? Here we answer both questions by studying an\n",
      "attractor neural network in which inhibition and excitation balance each other.\n",
      "Using mean field analysis, we derive a three-variable description of attractor\n",
      "networks. From this description it follows that irregular firing can exist only\n",
      "if the number of neurons involved in a memory is large. The same mean field\n",
      "analysis also shows that the number of memories that can be stored in a network\n",
      "scales with the number of excitatory connections, a result that has been\n",
      "suggested for simple models but never shown for realistic ones. Both of these\n",
      "predictions are verified using simulations with large networks of spiking\n",
      "neurons.\n",
      "\n",
      "-----------------------------------\n",
      "  A new complex network model is proposed which is founded on growth with new\n",
      "connections being established proportionally to the current dynamical activity\n",
      "of each node, which can be understood as a generalization of the\n",
      "Barabasi-Albert static model. By using several topological measurements, as\n",
      "well as optimal multivariate methods (canonical analysis and maximum likelihood\n",
      "decision), we show that this new model provides, among several other\n",
      "theoretical types of networks including Watts-Strogatz small-world networks,\n",
      "the greatest compatibility with three real-world cortical networks.\n",
      "\n",
      "-----------------------------------\n",
      "  We present morphological classifications obtained using machine learning for\n",
      "objects in SDSS DR6 that have been classified by Galaxy Zoo into three classes,\n",
      "namely early types, spirals and point sources/artifacts. An artificial neural\n",
      "network is trained on a subset of objects classified by the human eye and we\n",
      "test whether the machine learning algorithm can reproduce the human\n",
      "classifications for the rest of the sample. We find that the success of the\n",
      "neural network in matching the human classifications depends crucially on the\n",
      "set of input parameters chosen for the machine-learning algorithm. The colours\n",
      "and parameters associated with profile-fitting are reasonable in separating the\n",
      "objects into three classes. However, these results are considerably improved\n",
      "when adding adaptive shape parameters as well as concentration and texture. The\n",
      "adaptive moments, concentration and texture parameters alone cannot distinguish\n",
      "between early type galaxies and the point sources/artifacts. Using a set of\n",
      "twelve parameters, the neural network is able to reproduce the human\n",
      "classifications to better than 90% for all three morphological classes. We find\n",
      "that using a training set that is incomplete in magnitude does not degrade our\n",
      "results given our particular choice of the input parameters to the network. We\n",
      "conclude that it is promising to use machine- learning algorithms to perform\n",
      "morphological classification for the next generation of wide-field imaging\n",
      "surveys and that the Galaxy Zoo catalogue provides an invaluable training set\n",
      "for such purposes.\n",
      "\n",
      "-----------------------------------\n",
      "  This work clarifies the relation between network circuit (topology) and\n",
      "behavior (information transmission and synchronization) in active networks,\n",
      "e.g. neural networks. As an application, we show how to determine a network\n",
      "topology that is optimal for information transmission. By optimal, we mean that\n",
      "the network is able to transmit a large amount of information, it possesses a\n",
      "large number of communication channels, and it is robust under large variations\n",
      "of the network coupling configuration. This theoretical approach is general and\n",
      "does not depend on the particular dynamic of the elements forming the network,\n",
      "since the network topology can be determined by finding a Laplacian matrix (the\n",
      "matrix that describes the connections and the coupling strengths among the\n",
      "elements) whose eigenvalues satisfy some special conditions. To illustrate our\n",
      "ideas and theoretical approaches, we use neural networks of electrically\n",
      "connected chaotic Hindmarsh-Rose neurons.\n",
      "\n",
      "-----------------------------------\n",
      "  We investigate the dynamics of continuous attractor neural networks (CANNs).\n",
      "Due to the translational invariance of their neuronal interactions, CANNs can\n",
      "hold a continuous family of stationary states. We systematically explore how\n",
      "their neutral stability facilitates the tracking performance of a CANN, which\n",
      "is believed to have wide applications in brain functions. We develop a\n",
      "perturbative approach that utilizes the dominant movement of the network\n",
      "stationary states in the state space. We quantify the distortions of the bump\n",
      "shape during tracking, and study their effects on the tracking performance.\n",
      "Results are obtained on the maximum speed for a moving stimulus to be\n",
      "trackable, and the reaction time to catch up an abrupt change in stimulus.\n",
      "\n",
      "-----------------------------------\n",
      "  The effects of dominant sequential interactions are investigated in an\n",
      "exactly solvable feed-forward layered neural network model of binary units and\n",
      "patterns near saturation in which the interaction consists of a Hebbian part\n",
      "and a symmetric sequential term. Phase diagrams of stationary states are\n",
      "obtained and a new phase of cyclic correlated states of period two is found for\n",
      "a weak Hebbian term, independently of the number of condensed patterns $c$.\n",
      "\n",
      "-----------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>relevance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9979</th>\n",
       "      <td>Neural network model with discrete and continu...</td>\n",
       "      <td>An associative memory model and a neural net...</td>\n",
       "      <td>0.808772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5521</th>\n",
       "      <td>Learning of correlated patterns by simple perc...</td>\n",
       "      <td>Learning behavior of simple perceptrons is a...</td>\n",
       "      <td>0.804218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16765</th>\n",
       "      <td>Theory and modeling of the magnetic field meas...</td>\n",
       "      <td>The magnetic diagnostics subsystem of the LI...</td>\n",
       "      <td>0.797617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7466</th>\n",
       "      <td>A Growing Self-Organizing Network for Reconstr...</td>\n",
       "      <td>Self-organizing networks such as Neural Gas,...</td>\n",
       "      <td>0.786276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>A balanced memory network</td>\n",
       "      <td>A fundamental problem in neuroscience is und...</td>\n",
       "      <td>0.780160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12539</th>\n",
       "      <td>Modeling Connectivity in Terms of Network Acti...</td>\n",
       "      <td>A new complex network model is proposed whic...</td>\n",
       "      <td>0.777826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16033</th>\n",
       "      <td>Galaxy Zoo: Reproducing Galaxy Morphologies Vi...</td>\n",
       "      <td>We present morphological classifications obt...</td>\n",
       "      <td>0.776197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3732</th>\n",
       "      <td>Optimal network topologies for information tra...</td>\n",
       "      <td>This work clarifies the relation between net...</td>\n",
       "      <td>0.773260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2939</th>\n",
       "      <td>Dynamics of Neural Networks with Continuous At...</td>\n",
       "      <td>We investigate the dynamics of continuous at...</td>\n",
       "      <td>0.769132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>Period-two cycles in a feed-forward layered ne...</td>\n",
       "      <td>The effects of dominant sequential interacti...</td>\n",
       "      <td>0.768802</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "9979   Neural network model with discrete and continu...   \n",
       "5521   Learning of correlated patterns by simple perc...   \n",
       "16765  Theory and modeling of the magnetic field meas...   \n",
       "7466   A Growing Self-Organizing Network for Reconstr...   \n",
       "227                            A balanced memory network   \n",
       "12539  Modeling Connectivity in Terms of Network Acti...   \n",
       "16033  Galaxy Zoo: Reproducing Galaxy Morphologies Vi...   \n",
       "3732   Optimal network topologies for information tra...   \n",
       "2939   Dynamics of Neural Networks with Continuous At...   \n",
       "194    Period-two cycles in a feed-forward layered ne...   \n",
       "\n",
       "                                                abstract  relevance  \n",
       "9979     An associative memory model and a neural net...   0.808772  \n",
       "5521     Learning behavior of simple perceptrons is a...   0.804218  \n",
       "16765    The magnetic diagnostics subsystem of the LI...   0.797617  \n",
       "7466     Self-organizing networks such as Neural Gas,...   0.786276  \n",
       "227      A fundamental problem in neuroscience is und...   0.780160  \n",
       "12539    A new complex network model is proposed whic...   0.777826  \n",
       "16033    We present morphological classifications obt...   0.776197  \n",
       "3732     This work clarifies the relation between net...   0.773260  \n",
       "2939     We investigate the dynamics of continuous at...   0.769132  \n",
       "194      The effects of dominant sequential interacti...   0.768802  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finder.predict_query('neural network', True, 0.7)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
