{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "\n",
    "from my_nlp_library import MyTokenizer\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "\n",
    "#  Carregando os embeddings do GloVe\n",
    "def load_glove_vectors(glove_file):\n",
    "    glove_vectors = {}\n",
    "    with open(glove_file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            vector = torch.tensor([float(val) for val in values[1:]], dtype=torch.float32)\n",
    "            glove_vectors[word] = vector\n",
    "    return glove_vectors\n",
    "\n",
    "\n",
    "def get_vocabulary_from_glove(glove_vectors):\n",
    "    vocab = dict()\n",
    "    inverse_vocab = list()\n",
    "    vocab[\"<PAD>\"] = 0\n",
    "    inverse_vocab.append(\"<PAD>\")\n",
    "    vocab[\"<UNK>\"] = 1\n",
    "    inverse_vocab.append(\"<UNK>\")\n",
    "    for word, vector in glove_vectors.items():\n",
    "        vocab[word] = len(inverse_vocab)\n",
    "        inverse_vocab.append(word)\n",
    "    return vocab, inverse_vocab\n",
    "\n",
    "\n",
    "\n",
    "class Glove():\n",
    "    def __init__(self):\n",
    "        self.glove_vectors = load_glove_vectors(\"data/glove.6B.300d.txt\" )\n",
    "        vocab, inverse_vocab = get_vocabulary_from_glove(self.glove_vectors)\n",
    "        self.vocab = vocab\n",
    "        self.inverse_vocab = inverse_vocab\n",
    "        self.embedding_dim = 300\n",
    "        self.embeddings_matrix = self.create_embedding_matrix()\n",
    "        print(\"Glove embeddings loaded.\")\n",
    "\n",
    "\n",
    "    def create_embedding_matrix(self):\n",
    "        vocab_size = len(self.glove_vectors) + 2\n",
    "        embedding_glove = nn.Embedding(vocab_size, self.embedding_dim)\n",
    "\n",
    "        for idx, word in enumerate(self.inverse_vocab[2:]):\n",
    "            i = idx + 2\n",
    "            embedding_glove.weight[idx].data = self.glove_vectors[word]\n",
    "        return embedding_glove\n",
    "        \n",
    "    \n",
    "    def get_embedding_matrix(self):\n",
    "        return self.embedding_matrix\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "class PreparaTexto(nn.Module ):\n",
    "    def __init__(self, tokenizer, embedding_layer):\n",
    "        super().__init__()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.embedding_layer = embedding_layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Tokenize\n",
    "        tokens = self.tokenizer(x)\n",
    "        tokens = np.array(tokens)\n",
    "        mask = tokens > 1\n",
    "        x = torch.tensor(tokens)\n",
    "        x = self.embedding_layer(x)\n",
    "        pooled = torch.mean(x[mask], dim=0)\n",
    "        return pooled\n",
    "    \n",
    "\n",
    "class Transformador( nn.Module ):\n",
    "    def __init__(self, n_inputs, n_hidden):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(n_inputs, n_hidden)\n",
    "        self.layer2 = nn.Linear(n_hidden, n_inputs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.layer1(x)\n",
    "        z = self.layer2(h)\n",
    "        return z, h\n",
    "    \n",
    "class Database:\n",
    "    def __init__(self):\n",
    "        self.df = pd.read_csv(\"data/arxiv3.csv\")\n",
    "        self.embeddings_matrix = torch.load(\"data/embeddings_matrix.pt\", weights_only=True)\n",
    "\n",
    "\n",
    "class FinderModel:\n",
    "\n",
    "    def __init__(self):\n",
    "        # load data from embeddings_matrix.pt\n",
    "        self.data = Database()\n",
    "        self.glove = Glove()\n",
    "        self.tokenizer =  MyTokenizer(sentence_length=800, case_sensitive=False, vocab=self.glove.vocab, inverse_vocab=self.glove.inverse_vocab)\n",
    "        self.preparador = PreparaTexto(self.tokenizer, self.glove.embeddings_matrix)\n",
    "        self.model = Transformador(300, 200)\n",
    "        self.model.load_state_dict(torch.load(\"data/model.pth\", weights_only=True))\n",
    "        print('Model loaded')\n",
    "\n",
    "    def predict(self, query):\n",
    "\n",
    "        query_embedding = self.preparador(query)\n",
    "        query_processed = self.model(query_embedding)[1].detach().numpy() \n",
    "\n",
    "        query_processed_ = normalize(query_processed.reshape(1, -1))\n",
    "\n",
    "        embeddings_matrix_ = normalize(self.data.embeddings_matrix)   \n",
    "        \n",
    "        R = embeddings_matrix_ @ query_processed_.T\n",
    "\n",
    "        df_ = self.data.df.copy()\n",
    "        relevance = R.flatten()\n",
    "        df_[\"relevance\"] = relevance\n",
    "\n",
    "        df_filtered = df_[relevance > 0.00]\n",
    "        df_final = df_filtered.sort_values(\"relevance\", ascending=False)\n",
    "\n",
    "        # Selecionar colunas de interesse\n",
    "        df_final = df_final[['title', 'abstract', 'relevance']]\n",
    "\n",
    "        # print the top 10 abstracts\n",
    "        tam = min(10, len(df_final))\n",
    "        for i in range(tam):\n",
    "            print(df_final['abstract'].iloc[i])\n",
    "            print('-----------------------------------')\n",
    "            \n",
    "        return df_final.head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finder = FinderModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print it prettier\n",
    "import json\n",
    "\n",
    "finder.predict(\"neural network\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "finder.predict(\"relational database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "finder.predict(\"natural language processing\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
